{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e3c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from chromadb import PersistentClient\n",
    "from chromadb.utils import embedding_functions\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c0791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zipfiles',)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(r\"C:\\Users\\SRINU\\Downloads\\eng_subtitles_database.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777318ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num\n",
      "name\n",
      "content\n"
     ]
    }
   ],
   "source": [
    "# Reading the columns of Table\n",
    "cursor.execute(\"PRAGMA table_info('zipfiles')\")\n",
    "cols = cursor.fetchall()\n",
    "for col in cols:\n",
    "    print(col[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e073f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9180533</td>\n",
       "      <td>the.message.(1976).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x1c\\xa9\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9180583</td>\n",
       "      <td>here.comes.the.grump.s01.e09.joltin.jack.in.bo...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x17\\xb9\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9180592</td>\n",
       "      <td>yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00L\\xb9\\x99V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9180594</td>\n",
       "      <td>yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00U\\xa9\\x99V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9180600</td>\n",
       "      <td>broker.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x001\\xa9\\x99V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                                               name  \\\n",
       "0  9180533                         the.message.(1976).eng.1cd   \n",
       "1  9180583  here.comes.the.grump.s01.e09.joltin.jack.in.bo...   \n",
       "2  9180592    yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd   \n",
       "3  9180594    yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd   \n",
       "4  9180600                              broker.(2022).eng.1cd   \n",
       "\n",
       "                                             content  \n",
       "0  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x1c\\xa9\\x...  \n",
       "1  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x17\\xb9\\x...  \n",
       "2  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00L\\xb9\\x99V...  \n",
       "3  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00U\\xa9\\x99V...  \n",
       "4  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x001\\xa9\\x99V...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Database Table inside a Pandas DataFrame\n",
    "df = pd.read_sql_query(\"\"\"SELECT * FROM zipfiles\"\"\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the above Function on the Entire Data\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "count = 0\n",
    "\n",
    "def decode_method(binary_data):\n",
    "    global count\n",
    "    # Decompress the binary data using the zipfile module\n",
    "    # print(count, end=\" \")\n",
    "    count += 1\n",
    "    with io.BytesIO(binary_data) as f:\n",
    "        with zipfile.ZipFile(f, 'r') as zip_file:\n",
    "            # Assuming there's only one file in the ZIP archive\n",
    "            subtitle_content = zip_file.read(zip_file.namelist()[0])\n",
    "\n",
    "    # Now 'subtitle_content' should contain the extracted subtitle content\n",
    "    return subtitle_content.decode('latin-1')  # Assuming the content is UTF-8 encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9a0089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>file_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9180533</td>\n",
       "      <td>the.message.(1976).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x1c\\xa9\\x...</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9180583</td>\n",
       "      <td>here.comes.the.grump.s01.e09.joltin.jack.in.bo...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x17\\xb9\\x...</td>\n",
       "      <td>1\\r\\n00:00:29,359 --&gt; 00:00:32,048\\r\\nAh! Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9180592</td>\n",
       "      <td>yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00L\\xb9\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:53,200 --&gt; 00:00:56,030\\r\\n&lt;i&gt;Yumi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9180594</td>\n",
       "      <td>yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00U\\xa9\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9180600</td>\n",
       "      <td>broker.(2022).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x001\\xa9\\x99V...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                                               name  \\\n",
       "0  9180533                         the.message.(1976).eng.1cd   \n",
       "1  9180583  here.comes.the.grump.s01.e09.joltin.jack.in.bo...   \n",
       "2  9180592    yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd   \n",
       "3  9180594    yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd   \n",
       "4  9180600                              broker.(2022).eng.1cd   \n",
       "\n",
       "                                             content  \\\n",
       "0  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x1c\\xa9\\x...   \n",
       "1  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x17\\xb9\\x...   \n",
       "2  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00L\\xb9\\x99V...   \n",
       "3  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00U\\xa9\\x99V...   \n",
       "4  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x001\\xa9\\x99V...   \n",
       "\n",
       "                                        file_content  \n",
       "0  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...  \n",
       "1  1\\r\\n00:00:29,359 --> 00:00:32,048\\r\\nAh! Ther...  \n",
       "2  1\\r\\n00:00:53,200 --> 00:00:56,030\\r\\n<i>Yumi'...  \n",
       "3  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...  \n",
       "4  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file_content'] = df['content'].apply(decode_method)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a666d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24749, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>file_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17262</th>\n",
       "      <td>9251120</td>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>9211589</td>\n",
       "      <td>down.the.shore.s01.e10.and.justice.for.all.(19...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:09,275 --&gt; 00:00:11,876\\r\\n¶ Oh, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47707</th>\n",
       "      <td>9380845</td>\n",
       "      <td>uncontrollably.fond.s01.e07.heartache.(2016).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...</td>\n",
       "      <td>1\\r\\n00:00:07,140 --&gt; 00:00:14,220\\r\\n&lt;i&gt;Timin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29914</th>\n",
       "      <td>9301436</td>\n",
       "      <td>screen.two.s13.e04.the.precious.blood.(1996).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:06,133 --&gt; 00:00:08,900\\r\\n[etherea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54266</th>\n",
       "      <td>9408707</td>\n",
       "      <td>battlebots.(2015).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4&lt;\\x9aV...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:01,480 --&gt; 00:00:03,570\\r\\n[Chri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num                                               name  \\\n",
       "17262  9251120                     maybe.this.time.(2014).eng.1cd   \n",
       "7294   9211589  down.the.shore.s01.e10.and.justice.for.all.(19...   \n",
       "47707  9380845  uncontrollably.fond.s01.e07.heartache.(2016).e...   \n",
       "29914  9301436  screen.two.s13.e04.the.precious.blood.(1996).e...   \n",
       "54266  9408707                          battlebots.(2015).eng.1cd   \n",
       "\n",
       "                                                 content  \\\n",
       "17262  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...   \n",
       "7294   b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...   \n",
       "47707  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...   \n",
       "29914  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...   \n",
       "54266  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4<\\x9aV...   \n",
       "\n",
       "                                            file_content  \n",
       "17262  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...  \n",
       "7294   1\\r\\n00:00:09,275 --> 00:00:11,876\\r\\n¶ Oh, I ...  \n",
       "47707  1\\r\\n00:00:07,140 --> 00:00:14,220\\r\\n<i>Timin...  \n",
       "29914  1\\r\\n00:00:06,133 --> 00:00:08,900\\r\\n[etherea...  \n",
       "54266  ï»¿1\\r\\n00:00:01,480 --> 00:00:03,570\\r\\n[Chri...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_df = df.sample(frac=0.3, random_state=42)\n",
    "\n",
    "print(random_df.shape)\n",
    "\n",
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74eb51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df.to_csv(\"random_sampled_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed3480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRINU\\\\Downloads'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f314a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r\"random_sampled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77440d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24749, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>file_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9251120</td>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9211589</td>\n",
       "      <td>down.the.shore.s01.e10.and.justice.for.all.(19...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:09,275 --&gt; 00:00:11,876\\r\\n¶ Oh, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9380845</td>\n",
       "      <td>uncontrollably.fond.s01.e07.heartache.(2016).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...</td>\n",
       "      <td>1\\r\\n00:00:07,140 --&gt; 00:00:14,220\\r\\n&lt;i&gt;Timin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9301436</td>\n",
       "      <td>screen.two.s13.e04.the.precious.blood.(1996).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:06,133 --&gt; 00:00:08,900\\r\\n[etherea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9408707</td>\n",
       "      <td>battlebots.(2015).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4&lt;\\x9aV...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:01,480 --&gt; 00:00:03,570\\r\\n[Chri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                                               name  \\\n",
       "0  9251120                     maybe.this.time.(2014).eng.1cd   \n",
       "1  9211589  down.the.shore.s01.e10.and.justice.for.all.(19...   \n",
       "2  9380845  uncontrollably.fond.s01.e07.heartache.(2016).e...   \n",
       "3  9301436  screen.two.s13.e04.the.precious.blood.(1996).e...   \n",
       "4  9408707                          battlebots.(2015).eng.1cd   \n",
       "\n",
       "                                             content  \\\n",
       "0  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...   \n",
       "1  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...   \n",
       "2  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...   \n",
       "3  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...   \n",
       "4  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4<\\x9aV...   \n",
       "\n",
       "                                        file_content  \n",
       "0  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...  \n",
       "1  1\\r\\n00:00:09,275 --> 00:00:11,876\\r\\n¶ Oh, I ...  \n",
       "2  1\\r\\n00:00:07,140 --> 00:00:14,220\\r\\n<i>Timin...  \n",
       "3  1\\r\\n00:00:06,133 --> 00:00:08,900\\r\\n[etherea...  \n",
       "4  ï»¿1\\r\\n00:00:01,480 --> 00:00:03,570\\r\\n[Chri...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c00d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SRINU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SRINU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SRINU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d1f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subtitle(subtitle):\n",
    "    # Remove timestamps\n",
    "    clean_content = re.sub(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n?', '', subtitle)\n",
    "\n",
    "    # Remove other non-textual patterns\n",
    "    clean_content = re.sub(r'<[^>]+>', '', clean_content)\n",
    "\n",
    "    clean_content = re.sub(r\"[^\\w\\s]\", '', clean_content)\n",
    "\n",
    "    clean_content = re.sub(r\"[^\\x00-\\x7F]+\", '', clean_content)\n",
    "\n",
    "    clean_content = re.sub(r\"\\b\\d+\\s\", '', clean_content)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    clean_content = clean_content.lower()\n",
    "\n",
    "    # Tokenize the subtitle content\n",
    "    tokens = word_tokenize(clean_content)\n",
    "\n",
    "    # Remove stopwords and lemmatize tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    clean_content = ' '.join(clean_tokens)\n",
    "\n",
    "    return clean_content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87c5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned_content'] = df1['file_content'].apply(clean_subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5fb30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>file_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9251120</td>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "      <td>watch video online opensubtitles free browser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9211589</td>\n",
       "      <td>down.the.shore.s01.e10.and.justice.for.all.(19...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:09,275 --&gt; 00:00:11,876\\r\\n¶ Oh, I ...</td>\n",
       "      <td>oh know getting late dont wan na go home im hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9380845</td>\n",
       "      <td>uncontrollably.fond.s01.e07.heartache.(2016).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...</td>\n",
       "      <td>1\\r\\n00:00:07,140 --&gt; 00:00:14,220\\r\\n&lt;i&gt;Timin...</td>\n",
       "      <td>timing subtitle uncontrollable lovebird team v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9301436</td>\n",
       "      <td>screen.two.s13.e04.the.precious.blood.(1996).e...</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...</td>\n",
       "      <td>1\\r\\n00:00:06,133 --&gt; 00:00:08,900\\r\\n[etherea...</td>\n",
       "      <td>ethereal music apiopensubtitlesorg deprecated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9408707</td>\n",
       "      <td>battlebots.(2015).eng.1cd</td>\n",
       "      <td>b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4&lt;\\x9aV...</td>\n",
       "      <td>ï»¿1\\r\\n00:00:01,480 --&gt; 00:00:03,570\\r\\n[Chri...</td>\n",
       "      <td>chris oh minibots yelling oh leave little bot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                                               name  \\\n",
       "0  9251120                     maybe.this.time.(2014).eng.1cd   \n",
       "1  9211589  down.the.shore.s01.e10.and.justice.for.all.(19...   \n",
       "2  9380845  uncontrollably.fond.s01.e07.heartache.(2016).e...   \n",
       "3  9301436  screen.two.s13.e04.the.precious.blood.(1996).e...   \n",
       "4  9408707                          battlebots.(2015).eng.1cd   \n",
       "\n",
       "                                             content  \\\n",
       "0  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x89\\x9a\\x...   \n",
       "1  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x007\\x8f\\x99V...   \n",
       "2  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\x8f\\x19\\x...   \n",
       "3  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00[\\xaa\\x99V...   \n",
       "4  b'PK\\x03\\x04\\x14\\x00\\x00\\x00\\x08\\x00\\xf4<\\x9aV...   \n",
       "\n",
       "                                        file_content  \\\n",
       "0  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...   \n",
       "1  1\\r\\n00:00:09,275 --> 00:00:11,876\\r\\n¶ Oh, I ...   \n",
       "2  1\\r\\n00:00:07,140 --> 00:00:14,220\\r\\n<i>Timin...   \n",
       "3  1\\r\\n00:00:06,133 --> 00:00:08,900\\r\\n[etherea...   \n",
       "4  ï»¿1\\r\\n00:00:01,480 --> 00:00:03,570\\r\\n[Chri...   \n",
       "\n",
       "                                     cleaned_content  \n",
       "0  watch video online opensubtitles free browser ...  \n",
       "1  oh know getting late dont wan na go home im hu...  \n",
       "2  timing subtitle uncontrollable lovebird team v...  \n",
       "3  ethereal music apiopensubtitlesorg deprecated ...  \n",
       "4  chris oh minibots yelling oh leave little bot ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eae25f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24749, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62cab9",
   "metadata": {},
   "source": [
    "### **4. (Must Implement) A very important step to improve the performance: Document Chunker.**\n",
    "\n",
    "a. Consider the challenge of embedding large documents: Information Loss.\n",
    "\n",
    "b. It is often not practical to embed an entire document as a single vector, particularly when dealing with long documents.\n",
    "\n",
    "c. Solution: Divide a large document into smaller, more manageable chunks for embedding.\n",
    "\n",
    "d. Another Problem: Let’s say we set the token window to be 500, then we’d expect each chunk to be just below 500 tokens. One common concern of this method is that we might accidentally cut off some important text between chunks, splitting up the context. To mitigate this, we can set overlapping windows with a specified amount of tokens to overlap so we have tokens shared between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3693a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"cleaned_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bbf53c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRINU\\\\Downloads'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "716094c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read CSV file with specified encoding and handle missing values\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSRINU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, na_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file with specified encoding and handle missing values\n",
    "df = pd.read_csv(r\"C:\\Users\\SRINU\\Downloads\\cleaned_data.csv\", encoding=\"utf-8\", na_values=['NA', 'N/A'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4ba31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82498, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20cd6354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cleaned_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate through data and count tokens for each file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, entry \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 11\u001b[0m     total_tokens \u001b[38;5;241m=\u001b[39m count_tokens(entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_content\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Number of Tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_content'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to count tokens\n",
    "def count_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Iterate through data and count tokens for each file\n",
    "for index, entry in df.iterrows():\n",
    "    total_tokens = count_tokens(entry[\"cleaned_content\"])\n",
    "    print(f\"File: {entry['name']}, Number of Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the document chunker function\n",
    "def document_chunker(document, chunk_size=1500, overlap_size=200):\n",
    "    tokens = word_tokenize(document)  # Tokenize the document\n",
    "    num_tokens = len(tokens)\n",
    "    chunks = []\n",
    "\n",
    "    # Iterate over the tokens and create chunks with specified overlap\n",
    "    for start in range(0, num_tokens, chunk_size - overlap_size):\n",
    "        end = min(start + chunk_size, num_tokens)\n",
    "        chunk = tokens[start:end]\n",
    "        chunks.append({'name': row['name'], 'chunk_index': len(chunks) + 1, 'chunk_text': ' '.join(chunk)})\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e56c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the document chunker function\n",
    "def document_chunker(document, chunk_size=1500, overlap_size=200):\n",
    "    tokens = word_tokenize(document)  # Tokenize the document\n",
    "    num_tokens = len(tokens)\n",
    "    chunks = []\n",
    "\n",
    "    # Iterate over the tokens and create chunks with specified overlap\n",
    "    for start in range(0, num_tokens, chunk_size - overlap_size):\n",
    "        end = min(start + chunk_size, num_tokens)\n",
    "        chunk = tokens[start:end]\n",
    "        chunks.append({'name': row['name'], 'chunk_index': len(chunks) + 1, 'chunk_text': ' '.join(chunk)})\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b93ce99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cleaned_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m all_chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 4\u001b[0m     document \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     document_chunks \u001b[38;5;241m=\u001b[39m document_chunker(document)\n\u001b[0;32m      6\u001b[0m     all_chunks\u001b[38;5;241m.\u001b[39mextend(document_chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_content'"
     ]
    }
   ],
   "source": [
    "# Apply the document chunker to each cleaned document in the DataFrame\n",
    "all_chunks = []\n",
    "for index, row in df.iterrows():\n",
    "    document = row['cleaned_content']\n",
    "    document_chunks = document_chunker(document)\n",
    "    all_chunks.extend(document_chunks)\n",
    "\n",
    "# Create a new DataFrame from the list of chunks\n",
    "chunks_df = pd.DataFrame(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b52097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks_df.shape)\n",
    "\n",
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0b69fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chunks_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunks_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunks_df' is not defined"
     ]
    }
   ],
   "source": [
    "chunks_df.to_csv(\"chunks_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c97df0",
   "metadata": {},
   "source": [
    "### **3. Experiment with the following to generate text vectors of subtitle documents:**\n",
    "\n",
    "a. BOW/TFIDFto generate sparse vector representations. Note that this will only help you to build a Keyword Based Search Engine.\n",
    "\n",
    "b. BERT based “SentenceTransformers” to generate embeddings which encode\n",
    " semantic information. This can help us build a Semantic Search Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6ac699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62637, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>1</td>\n",
       "      <td>watch video online opensubtitles free browser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>2</td>\n",
       "      <td>also answer question invest something trendy r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>3</td>\n",
       "      <td>kitchen thats learned cook hmm thats miss moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>4</td>\n",
       "      <td>take ah wow like newlywed maybe time itll lovi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maybe.this.time.(2014).eng.1cd</td>\n",
       "      <td>5</td>\n",
       "      <td>time maybe time love wont end two old friend m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  chunk_index  \\\n",
       "0  maybe.this.time.(2014).eng.1cd            1   \n",
       "1  maybe.this.time.(2014).eng.1cd            2   \n",
       "2  maybe.this.time.(2014).eng.1cd            3   \n",
       "3  maybe.this.time.(2014).eng.1cd            4   \n",
       "4  maybe.this.time.(2014).eng.1cd            5   \n",
       "\n",
       "                                          chunk_text  \n",
       "0  watch video online opensubtitles free browser ...  \n",
       "1  also answer question invest something trendy r...  \n",
       "2  kitchen thats learned cook hmm thats miss moni...  \n",
       "3  take ah wow like newlywed maybe time itll lovi...  \n",
       "4  time maybe time love wont end two old friend m...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\SRINU\\chunks_data.csv\")\n",
    "\n",
    "print(df1.shape)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b042ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advertise product brand contact wwwopensubtitlesorg today congratulation rabbi oh well rabbi wife asks tell im lasri send father warm gratitude chandelier beautiful im asked right educational method yeshiva headmaster turned complained yeshiva student went ski vacation ski vacation five day complained ignore keep theyre good men study excel wanted day break expel yeshiva unacceptable every time student finish mishna chapter theyll go trip school would stay empty gmara book would left unread corner torah headmaster asked correct educational method teach boy way impose mountain basin answer ill tell right method right method daniel paran dori medium darset present created written directed eliran malka creator main editor daniel paran directed maor zaguri new black gedaliah stop bugging sorry rabbi come need come well yesterday awesome im gedaliah hi im talus usually break ice begin date story first date rabbi ovadia wife told information im going study torah wont clean wont cook wont anything torah studying wont even build sukkah wont replace bulb wont take car shop wont touch rag nothing study torah thats told first date find sentence touching actually left pretty quickly gedaliah dont consider dropping opening line rabbi gave three year ago still best part okay forget want move room theyre going renovation replace pipe stay work dont mind one month temporary room wish move gedaliah im right dont call sorry rabbi room honor wish move im gedaliah good best im supposed move many time tell touch hat come avinoam wasnt purpose ill fix calm cant fix broke kneitsch fold cant fix broken kneitsch saying friend fix kneitsch dont worry trust avinoam dont friend broken kneitsch unrepairable gone tell cant fix cant fix kneitsch gone hat gone told ton time meir dont break kneitsch meir gentle weight dont break kneitsch broke kneitsch thank much laser stay hat hold avinoam hat mine upset yes upset avinoam hat whats took hat borsalino yell breaking kneitsch cheeky boy buy borsalino calling cheeky get hand apologize apologize ill kill dont ill burn cigarette say youre sorry want see let go want supposed move say rabbi bloch told must mistake there room seems though youre three room capacity five yes lasri told move room rabbi bloch already tight youre room three rest live five room sleep bunk bed also matter seniority didnt arrive yesterday lasri maybe also want seat next holy ark honor maybe take day think lasri complete saying wash dish dinner warm fire sage cautious remember something coal light burn cautious around coal burned bite bite fox sting sting scorpion hiss hiss seraph word like burning coal book father chapter mishna see happens dont waste time gedaliah talk privately please honest need help guy cant meet meet meet meir he tsa want room learn thing two thats rabbi he tsa hell die tsa youll help die married tsa okay honor dont want creature room listen he freaking dont want sleeping next internet jacket van dam shvan dam work well agree everything fine well whatever headmaster asking u future headmaster dont put cart horse already rabbi already tsa tormented saint devout haredi geek help anyone shouldve brought librarian shelf going put there room everything ill put machine table okay ill put biography book chess come put hold second ill also need mattress like sleep shall sleep ground eat bread salt started okayt started okay look gedaliah maybe rabbi bloch want let cross line one space dov setting line start good thing let go stove heated stubble raking school shamai get amazing simple genius simple unbelievable messenger becomes receiver question simple anyone know translation meir middle like mitzvah good tsdaka tsitsit tsuka tefilin know problem excuse problem dont think there logic word read though theyre word thats dont understand example okay say cant give charity night think like thats cant give charity night there logic there logic whats logic listen story rabbi hanina used give charity night hed night another night another night another night one day bang demon get say hanina stop giving charity night hanina look say excuse give charity whenever wherever see fit demon come closer say shall remove neighbor landmark hanina doesnt get come closer demon come closer come closer demon come closer theyre far start hitting poof demon disappears okay whats logic dont enter somebody el territory night territory demon ghost dont go mitzvah there time mitzvah there time demon wish get yeshiva back track wish get yeshiva back track tragedy weve feeling cant keep student whose feeling everyones everybody agrees reputation fallen past month educator education hard work take time patience rabbi bloch way ran yeshiva boy hanging coffee house delight mall etc want know dont chase send little supervisor instructor run around wrangle thats method seems though method dont explain educational method u believe student supervisor mean exactly little hard explain mean exactly listen rabbi bloch right seven student registered next year seven student instead think explain mean exactly dear god seder already started seder isnt going anywhere gedaliah seder still chill itll got get dressed rabbi want move back old room dont care replace pipe electricity whatever go back gedaliah let talk later lot mind look really good guy want study mean seriously fooling around need atmosphere teireh torah yiddish dialect atmosphere teireh rabbi shach fact didnt wake prayer first time managed fine without move another room everything happened yeshiva yesterday really think deal room issue happened yesterday yeshiva sorry gedaliah enough come take lunch im sorry barbecue sacher park happened ask many question let go well back hour youll time seder come let go live buy watch want check cant believe oh seriously brought yes noticed didnt rabbi bloch ask help he tsa meir look meir seriously carrying around whole jewish book shelf come gedaliah commercial breakwe continue ultraorthodox world army recruitment yeshiva student father go knesset bus dont worry father talking bus drop line must late chavrusa hour kill avinoam look who unbelievable ashi shpitzer rabbi ashi shpitzer rabbi course youre never going forgive shiur klali gittin think yes question shiur klali gittin started making hard shpitzer tried break process thought thats learn avinoam tried make hard front everyone let eat dish saying front everyone question fit little kid thats humiliating shpitzer avinoam avinoam shpitzer avinoam havent seen missed safe ride respect scholar whats wrong feel respect person never gedaliah look place feel comfortable home stop feeling like haredi story come buy capsule hello good afternoon hello need couple box capsule model first latisima frothing function orange u first orange u latisima difference make meir yellow pixie really like really okay okay need sleeve purple plastic capsule meir theyre plastic aluminum purple capsule exactly excellent good loved fruity scent heard new blend african yes capsule fit nespressos machine sure machine nespresso yes yes yes sure bought say whats kosher certification rabbinate thats think maybe religious court justice one haredi mahfud gedaliah okay make mind well take want three sleeve arpeggio two restreto whats hard understand well written anywhere please find hatam sofer beit yosef hello im checking please patient e dont buy store gedaliah hear word tact saying cant go store start yelling kosher certificate bother doesnt bother bother store atmosphere oh bother store atmosphere see know didnt care one bit avinoam yes true avinoam didnt care meir id upset someone came store started questioning kosher certification rabbinate court justice haredi megadim beit yosef hatam sofer rabbi mahfud rubin youre haredi yes avinoam even acted beautifully kept quiet like youre class tried flatter fruity scent still little one little one pee look gedaliah want tell something yes segregate convenient alone studying torah day long want part story part whats happening dont want observer get fuck listen take ball go elsewhere barbecue calm first move car barbecue tell whats problem bother barbecue whats wrong man dont tell whats wrong fuck tell fuck right fuck avinoam thought friend tell want part story stop pushing pushing holy work worth much torah study room avinoam think nice clothes suit zara hell want friend youre totally youll happy locked shed talmud book whats wrong great thats nobody want date know didnt say anything well chicken ready who first well think much one day im going back yeshiva gedaliah im going kick as whats wrong hey hey hey whats problem dont tell whats problem hear whats pleasant way friend way pleasant way fuck pleasant haredi piece shit say he joking meir he joking called u piece shit know let see got ball ball play u see haredi piece shit okay thats going easy get four play score one touchdown field e four try win field done okay ball first come let go mind theyre professional dont even know rule know rule complicated run ball side thats come ready let war balli gedaliah gedaliah gedaliah yarmulke yarmulke come come let go saw picked listen remembered something blood sport van dam say last fight peak nice innovation meir ok bring listen tell mr miagi many hit take many hit take still get hit back right let get hit back come there something'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['chunk_text'][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67b5e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eac785a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF for the documents\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df1['chunk_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae76fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"advertise product brand contact wwwopensubtitlesorg today congratulation rabbi oh well rabbi wife asks tell im lasri send father warm gratitude chandelier beautiful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c24fa061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_query = clean_subtitle(query)\n",
    "\n",
    "# Calculate TF-IDF for the query\n",
    "query_tfidf = tfidf_vectorizer.transform([cleaned_query])\n",
    "\n",
    "# Calculate cosine similarity between the query and documents\n",
    "cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
    "\n",
    "# Get the indices of documents sorted by similarity score\n",
    "sorted_indices = cosine_similarities.argsort()[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fa2fe34-5a60-47ad-a634-8516264c08c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38845, 60704, 38844, ..., 23699, 61786, 48922], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c46402b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar chunk_text:\n",
      "Document 1: checkout good im staying right time world congratulation praise god keep safe huh mole loose god willing pack transport im going turn ac car rabbi kohava keep eye rabbi im going get cooler sure thing got said got wont puncture tire anymore mother word excuse anyone hello give gram minced meat please im working today maam came get something nissim favor give meat go there one nissim thank much gram minced meat gram parrot look exactly like pharmacy wait want angus instead worthwhile fine fine maam take gram get discount dont want bigger cut good good good go anything else keep fridge ill right back goodbye thank kohava kohava rabbi waiting outside anatoly came get charger hows going wheres rabbi rabbi rabbi ekron son arye supervisor never come rump steak dont shout ground lady asked keep cold ground rabbi ekron son arye ground rabbi sweetie im telling shes coming school tomorrow shoe bye sweetie bye whats sourpuss asked watch rabbi said got talking talking jessicas teacher ready whats going wheres rabbi ground rabbi dont believe rabbi ground ground rabbi didnt grind rabbi ground steak told touch day even idiot damn drain put rabbi skewer pound dont grind rabbi rabbi ekron closing balcony weekend burgas come get phone charger rabbi rabbi dont see rabbi slang hebrew bro ground rabbi messed rabbi dont understand joke rabbi rabbi look like saint sanaa oh look hold meni beeger singer like nissim garame singer look profile nissim garame saint eireles give tihat ment beger walt idiot kohava let se wait let see check ompostor impostor advertise product brand contact wwwopensubtitlesorg today\n",
      "Document 2: first condition acceptable second condition would change last name something le sephardic want work father know heart tell moroccan take particularly hard also widower pas personal please wow signed headmaster decided wanted join rabbinical study woman law object would person love torah oppose sorry deborah wrong understood everyone need one thing b c day upon king day fun youre interesting wow work gap big work end gd invented matchmaker raven fall love bird ultraorthodox marry secularist power confusion put ring someone finger tell yes ill bring someone smile le beautiful sometimes hate haredi much want asked slide right wrong true like like cool grandfather money money everything life grandfather doesnt money money grandfather square named jerusalem grandfather bank brazil understand im telling grandfather donated marans book yes matter end surrender understand rich girl dependent father characterless spoiled look horrible want classic seminar girl dont want youve seen yet know show picture show picture mother allow seriously saw picture trust trust shlomi zacks tell dress nicely go date happens tell shes classic seminar girl zacks youre manipulating manipulating know thats think favor really trust go go confirm zimel recommend trust want hear path go different way enough want know trust good okay ill go well ill go going im going im going moshe eh bring bottle one expensive shlomi stop lasri go date need celebrate raised dead bring new shirt celebrate fast zacks stop enough fast lasri go date believe happening arrive time dress nicely promise lasri go date sub ry ripped hebrew rysubripper httpsgithubcomarysoftplayrysubripper advertise product brand contact wwwopensubtitlesorg today rebel fine honored rabbi fine oh oh rabbi chaya bar abba fell ill rabbi yochanan entered asked like suffering like suffering like suffering like suffering replied neither suffering reward rabbi yochanan told rabbi yochanan answered give hand held honorable rabbi honorable rabbi leave u early like suffering gedalia shut already youre little sick take pill rest quietly one last request yes honored rabbi honored rabbi ask light beit midrash study recovery way might saved saved rabbi light trabelsi rabbi day dedicated healing committed right commited committed strengthen embrace people city god go fill beit midrash pressed button press press sholem aleichem sholem aleichem suit come dressed beit midrash come today say psalm place something today promised rabbi besides torah world sabag errand day two day dressed best brook brother top also abandoning rabbi difficult time shut whats going instead day mourning eulogy holy rabbi become holiday errand friend errand errand errand shame shame really pure shame headmaster abandoned die one die friend friend worry rabbi yabriya chick chek today day virtue prophet bakuk sorry habakkuk prophet fourth tribe every two people finish book psalm together three time scripture raise temple built day habakkuk prophet know virtue he working u fourth tribe work three time need two people say book psalm together three time day fourth tribe four square three circle circle square grace judgment one letter one letter g name ez yashir moshe complex rabbi medicine there doubt rabbi rise sickness small change addition said virtue quick mating trabelsi want ortal guetta another year raise succeed calculate correctly minute spare well able finish three time tonight question may chapter psalm healing teacher rabbi rabbi gedaliah son jehoiachin friedlander come ready amen amen come chapter blessed man walketh counsel ungodly way sin stand seat zim sit law god desire law kill day night chapter modern time psst psst hey hey story rabbi akiva rachel know rachel rich girl rabbi akiva shepherd walked around sheep sort place knew nothing nothing knew moment would come everything fine meyer everything fine come youve already told hand last name he coming anyway sign main obstacle already behind u yet realized something willing give inheritance million say crazy true true experience young believed believed one day would grow blossom would rabbi akiva willing pay price wait waited year take le sure hi oh im waiting noam kidan help carry couch leave come ill help really yes yes yes yes ok careful little broken house ok thank much avinoam sure didnt tell would finished meyer meyer well okay okay okay talk concentrate marriage part smell disaster shlomi everything fine enough enough relax floor say one floor strength oh yes yes yes sure want yell shout shout yes yes loud help exercise like release abdomen shouting shout ok ok three avinoam two one stronger ok ok stronger well listen youre cool really return scene afraid appreciate impossible really honestly ten reason like instinctively always gap remember yet going maternity ward gate justice see lot baby right get couple gap married parent found way get along simple go get dad go get dad come thought taking fun day hour quiet without neighbor laundry making lunch without oppressive city tel aviv throw trash trash trash youre good looking like like formal meeting like date oh ok wow must excited really im excited yes late nonsense nothing happen wait moment want u put de couch apartment leave avinoam avinoam really two free tip youre late girl never late girl ok two compliment look cant doesnt work u like compliment flatter know compliment body tell look good see dress nice understand much dont understand im jealous look everything simple like beer sofa happens need like walk around point hundred year like let like like like water soda tie red okay flatter eye get matter ultraorthodox secular get believe finish beer go noa hi noa safra eh hows life seminar im seminary excellent magnificent shall start oh start question shall go like like bake cake macrame pilate really familiar yes im impressed pilate yoga dog looking back know there fear stargazing coming east im pilate avinoam bow star ok music fried ben david shwekey truth im back coldplay show amsterdam two friend ok politics come question politics gimel shas two option ultraorthodox girl give apology father vote really truth told im quite surprised fancy beer beer beer let drink beer like water let drink beer actually beer beer yes determined drink water first date nobody fit rule youre still classic seminar girl excuse telling square ultraorthodox whats problem beer live modern time problem drinking beer first date say whats wrong happened said want drink beer celiac sorry noa im sorry wait minute came beginning prejudiced cohesive opinion give test admitted closed club say avinoam youre right im sorry place pressure know go u racist put label first moment saw decided im baking cake im voting gimel hear abraham fried matter hate im ultraorthodox breaking news lasri gedalia rest ill bother come deborah everyone visit patient take one sixtieth illness sure today im going great deborah come sorry listen second great pill homeopathic something really modern really help excellent bring pill way see maybe sign go opening day torah student already told going opening day rebbetzin shipris heard nehama enough rebbetzin shifris shes dead hears nothing instead getting upset time sticking cornflakes maybe help bride really problem problem waited year see meir wife minute nothing happen heard beauty indescribable definitely thought way today modern time sabag gottlieb getting married unbelievable brought grandfather ashkenazi would throw inheritance thing already different generation entirely different generation eh begin let u aligned talked meir closed wedding care meir decides acceptable oh bride oh heard city judah street jerusalem hello begin ive heard lot excuse tear eye thats fine hear meir one hand one thing see first time definately perfect beauty obsession completely pretty girl two hand street like garbage shall go eat yes please hear silence hear tel avivians know live come front sea already opening energy right feel talk saying thing normal noise hard say like bring fruit towel vegetable shit fuck becheks gang room next bechek care tsul doesnt know shut see u like posting home site haredi room come deborah im oh deborah youre deborah true sorry im nekhama partner yes yes fiance righteous sent bring homeopathic pill deborah come fiance righteous go opening day place want study torah persuaded bring pill true righteous yes yes said taken every two hour okay put put okay feel well best feel good best best best best feel well everybody student take care rabbi ah everyone beit midrash left headmaster alone rabbi eat something look pill new modern thing know helpful rabbi know really help know let resume resume resume resume ah say kind true remember wanted say wow thats open open open hershkovitz hi hi happy see im glad see heard youre setting yeshiva neighborhood infidel yes yes yes say may seen bechek friend told seat shuttle disappeared ishmaelites seem left related relationship tried park couldnt helped im way mourn ten accident parking lot around world nine involve woman completely driving test realized corrupt world besides never got along car whats wrong bus good day brown let go home want please take home absolutely abigail like cant work great start happen happen anywhere want explain blessed one sent u meeting eh gave u one meeting prove u wrong true gave u one meeting thats must end leizer\n",
      "Document 3: checkout issachar bounty miracle meat counter meat counter sunday hi hello id like entrecote please coming right customer dont like butt take whyre butting asked try express opinion meat counter whatever customer want sacred give nice cut barbeque barbeque entrecote dude take rump steak say rump steak better sure give rump steak many piece seven seven yes sevenll leave wanting take make whats barbeque gang hanging yarkon park yarkon park go new park herzliya go whats wrong thank god miracle day age pal alright alright better alright look see meat steak steak take closer look fat steak fat fat rabbi livelihood come around year generation wouldnt know pal wouldnt know call jewish look eye nose ear mouth famous mole uh listen dont give steak rabbi ekron sated rabbi livelihood supermarket year generation want steak thank god whoa dude pal many know year ago owner castro sold jean trunk one day rabbi ekron appeared button pair dungaree rest history im sorry stink known coming would tidied nissim customer tell there service meat counter forget customer shira need customer ah sorry dont understand youre showing jewish know rabbi ekron son arye safed rabbi livelihood supermarket look eye ear nose mouth famous mole fact people still worship dead people quote drivel came mouth sad steve job said best leave past hold future beautiful simple precise quoted dead man dead people dead people okay nissim respect faith know youre excited there nothing steak intelligent god help dont believe saint rabbi ekron son arye sshhh let touch bless heart issachar bounty excuse cant check employee birthday fire someone celebrate day try side im trying side try side give hand greasy pickle try side side got corner pickle try side side side youre like broken record turn side who sadist invented bag id crack head open could find side oh really people dont open take calm gentleness patience slowly slowly separate okay listen there method start corner nothing comer start corner hold go like foo need spit wait know try side know bag okay talam wouldnt happen levi plenty meat counter sunday help god nissim im sorry interrupt rabbi avner zada nissim butcher iv rabbi flesh honor two year ago aunt dying hospital one knew one night image rabbi vaknin e saint djerba appeared iv bag rabbi health yes appeared entirely half face honor yes asked rabbi zada verify false iv god forbid short sweet ruled rabbi djerba yes guess happened one month later yes aunt recovered recovered like brand new happy may god avenge blood may god avenge blood one month routine checkup crane came crashing head poof dead spot squished unexpected accident different saint baba ben tov netivot baba ben tov car accident youre confusing big eagle rabbi ventura big eagle general saint doesnt one specialty he jack trade go rabbi let inspect first verify saint sadly day impostor oh may go ahead rabbi careful mole rabbi saint calm routine he impostor wont survive well survive kosher kosher kosher tell huh didnt tell mean saint salvation blessing upon upon commission conundrum conundrum rabbi conundrum pay meat even little one coin meat blessing belong supermarket blessing upon manager hat supermarket rabbi due respect supermarket slice supermarket weight supermarket wrap salt make kosher rabbi mercy rabbi im going anywhere without blessing sshhh calm need angry case jewish law provides another option option instance transfer saint third party meaning meaning im tossing transfer cousin kabbalist pinhasov im sure youve heard yes course god fearing disciple study torah day night yes enjoy saint divine aura whoever vicinity blessed kohava want detach saint wait let hear obviously nicely rewarded discovery thats small potato need minute think think put steak cooler seal vacuum scared thank rabbi help chicken money saint decided lavish take saint could offended hell reveal somewhere else ill feel bad hen steve job launched first iphone spent budget packaging alone good manager understands product must packed look inviting whether iphone red pepper mendel bag existed year two month include factory ein tut nice produce finest bag market european standard american design japanese technology course bag using ummalkiel malkiel way got putting food malkiel bag pool phosphorus ill go phosphorus every time branch isnt like hope isnt bag different league carbon fiber resistant temperature freezing cold heat name digital print term environment biodegradable want feel feel look presto one madame may sure remembered factory ein tut feel fondle dont shy wow carbon fiber feel sure important guy first patent bag kind okay allows customer instantly detect opening call blow buy blow buy blow buy say ill take okay wheres contract checkbook aint game ramsey get checkbook instead sure blowing bag oh yeah baby cuckoo shirushka bag deluxe there there way say convenience happiness thats precious customer im glad hear shopping experience thank thats go steve job way cant miss know steve mystic connection steve born day day tuesday tuesday tuesday riki make want shop riki try smith riki im calling dont answer im shira thats asked call answer sorry huh field day didnt get chance tell avihai pretty exciting changed bag vegetable rack changed bag come roll easier open blow think im sadist think like giving customer bag rarely open choice give israeli good bag field day put one plum bag know hard get bag suck day god change winning horse father supermarket luckily thank god one manager bos daughter dont remember end week change bag malkiel one know riki shira get work youre bag support u become vip member remove ad wwwopensubtitlesorg excited threw malkiel bag garbage found one ill say bag extremely thin theyre called malkiel never open know maybe storeroom check hello big bos good news talked cousin netzer sireni branch malkiel bag doesnt even know he getting married he missing eye finally care cousin need malkiel bag end week thats problem huge problem none buyer bag theyre even legal put dumpster someone took love bag much love bag take garbage titinksy steinbuch get bag none business took garbage history professor id take thing garbage last week asked sell expired herring garbage history amnon bag theyre mine amnon return bag okay alright alright alright pay much five shekel five thousand bag theyre vintage he annoying he annoying dont want give bag theyre bag last offer mr titinsky one penny per bag excellent good thanks need ever since remember start day fresh yogurt either yogurt porridge mother used make yogurt people ask dont leave home tell im closed shes closed funny tell im glad find funny go tell tell shes glad find funny tell im done im going little girl room want there another checkout counter good say there another checkout counter good good funny huh okay problem excuse friend look like good guy would mind including yogurt purchase ill pay cash exact amount okay checkout okay go penny oh wait there supermarket birthday special every purchase get shekel discount hey cool brought luck totally totally say gim hug gim hug never anything yes got shekel bill ill pay back penny ill call mother tell pal hold didnt win anything okay purchase favor yogurt favor yogurt favor favor yogurt favor yogurt people stop press nice man favor yogurt ill call mother tell met nice man favor yogurt love customer fight like theater without falling asleep part pal yogurt wouldnt get discount favor youd stuck half hour nice come back indeed yogurt wouldnt know there special discovered thanks fine thanks okay youre columbus special thats okay cancel yogurt cancel yogurt say discount oh hero huh need columbus special get discount hey hold know gave thought youre right purchase please finish let following put yogurt give shekel special thanks yogurt shekel special put yogurt yogurt scum scum go go youll guilt feeling youth today huh gim yogurt ill let go really think im going little girl room want checkout good im staying right time world congratulation praise god keep safe huh mole loose god willing pack transport im going turn ac car rabbi kohava keep eye rabbi im going get cooler sure thing got said got wont puncture tire anymore mother word excuse anyone hello give gram minced meat please im working today maam came get something nissim favor give meat go there one nissim thank much gram minced meat gram parrot look exactly like pharmacy wait want angus instead worthwhile fine fine maam take gram get discount dont want bigger cut good good good go anything else keep fridge ill right back goodbye thank kohava kohava rabbi waiting outside anatoly came get charger hows going wheres rabbi rabbi rabbi ekron son arye supervisor never come rump steak dont shout ground lady asked keep cold ground rabbi ekron son arye ground rabbi sweetie im telling shes coming school tomorrow shoe bye sweetie bye whats sourpuss asked watch rabbi said got talking talking jessicas teacher ready whats going wheres rabbi ground rabbi dont believe rabbi ground ground rabbi didnt grind rabbi ground steak told touch day even idiot damn drain put rabbi skewer pound dont grind rabbi rabbi ekron\n",
      "Document 4: die tragedy life end stammer uh precious must end tell sigh sometimes faith mean must move forward without answer armed knowledge answer come time family member help fbi agent stand back understand anything harris goldblatt family member cant harris goldblatt sigh fbi youre arrest right remain silent zabler father passed away man mourning make easy harris stammer excuse whats going im rrabbi mr goldblatt arrest mr goldblatt bribery public official conspiracy commit bribery mr goldblatt harris racketeering extortion dont believe look whatever rabbi needed done sinking scoff evidently im one know fucking swim gabriela okay sweetie mean okay mr goldblatt would please stop stop wind whistling alpha hurricane stanley 41st storm landfall expected later week category hurricane bringing maximum sustained wind mile per hour storm surge approximately foot heavy rainfall lead flooding resident miami lowlying area encouraged seek higher ground marshall today alana goldblatt join congregation day bat mitzvah becomes daughter commandment becomes officially responsible action eye community god alana devoted student seeker truth today alana speak u destruction sodom gomorrah alana genesis know god burned sodom gomorrah ground killed people question deserve rabbi speak middah keneged middah let punishment fit crime selfish cruel materialistic lacking humility different u congregation murmuring come think god going let behavior slide flooding five day week house stilt city float body poor make mistake category retribution coming u mile hour name stan 41st storm year fuck covenant saith lord hey okay hey alana thats enough god going wipe planet clean start pick survive clearly dad hehe bribe public official dont time wait god judgment cry okay let take break thats called cop murmuring mr goldblatt could somebody stop marshall hey hey hey alana thats enough right ill remind daughter commandment honor father mother want remind thing relax fine alpha play marshall zucker well go back well july 17th live time crisis far environmentally displaced people need food water rest assured leader trying improve situation complicit like elie wiesel said must take side an8neutrality help oppressor never victim left israel didnt let refugee fend idea went israel left know stood right miami homeless dearly love lost shelter didnt know maybe didnt wan na know congregation murmuring thunder rumbling cant resign yeah course thats disgrace position letting 13yearold girl tell u world maybe rabbi least didnt sell homeless dont see problem somehow better people silently sink wave maybe alana goldblatt right maybe sodom gomorrah talking rabbi nobody turning pillar salt weve zoned preservation like said next year miami thunder rumbling fuck sigh dad going jail miami jail already flooded soon bat mitzvah shipped upstate raiford make orphan technically dad still one snorkel boat leaving soon alpha stanley make landfall alpha hurricane stanley expected make landfall pm storm surge expected exceed foot greater miami area sea wall thatll hold right biscayne bay sea wall built withstand storm surge foot knock alana honey max really need go think youd better leave sigh see know thunder rumbling fuck em saved synagogue think religion dont problem mom father would proud right know dont okay mom using avatar whats atabar sex thing stammer isnt uh sister help go back temple tell margo tillman mother know used give hand job golf pro maralago um look news saying evacuate mom right leave thought spiritual first responder people need people temple israel need rabbi mom im rabbi anymore cant hear sounded like said said im rabbi anymore go back temple tell electricity hum alpha civil defense alarm sea wall biscayne bay breached hurricane stanley please head higher ground sniffle clear throat marshall oh gasp chuckle hey hey didnt know call pump failing much water stammer torah oh sigh marshall grunt julia okay right grunting breathing heavily marshall ah siren wailing chuckle grunting strain grunt okay oh cover uh yeah yeah like exactly mean mean right chuckle work chuckle think right yeah got ta get grunting marshall storm descends town julia careful watch could could mine downpour soon turn flood water rise rabbi go synagogue save torah glass breaking julia grunt whoa marshall chuckle marshall rabbi go street moishe butcher come canoe better get rabbi car yeah water rising fast say rabbi faith lord save still water rise look rabbi um technically dont think im rabbi anymore thunder rumbling look helicopter whirring oh see u dont know hey hey hey hey hey pant go marshall grunt rabbi trying get torah higher ground benyamin tailor zip motorboat come rabbi need get outta levee gon na break minute julia grunt rabbi wave away believe torah lord see panting let help rabbi hey uh could call marshall id really appreciate marshall pant levee break flood rush town sweeping away everything path still rabbi cling torah water carry away end snagged highest branch highest tree storm helicopter appears julia oh hey state trooper call megaphone julia hey grab ladder rabbi last chance julia grunt rabbi insists lord deliver helicopter whirring predictably julia hey drowns pious man rabbi go heaven asks lord unwavering faith didnt deliver flood julia come rabbi finish god turn rabbi say well sent two boat helicopter want laughing guess homeless rabbi im sorry elijah made im glad youre alive chuckle uh hey rabbi never really answered question question might alana many god love u intervene much suffering yeah chuckle suck teeth moses asked god question much suffering youre powerful stop god give answer yeah inhales basically id tell wouldnt understand youre human im god thats thats answer human yeah think answer u marshall humming singin rain humming chuckling singin rain playing please rate subtitle wwwosdblinkcmj3a help user choose best subtitle\n",
      "Document 5: section okay here michaela here gabriela yaffaelas beat huh well here money renovation tomorrow morning deposit synagogue account withdraw cash bring got sure dont worry ill take care giving money lot postdated check know people gave could well done deposit synagogue account problem rabbi tell tell woman keep calling fixing woman section tell first congratulate fine effort simple aaron tell many religious issue involved building synagogue look deeply patiently dont end sinning god forbid oh best understand margalit im listening arent listening shh lot postdated check supposed problem youre always hurry itll take day day dont move money contractor wait want start building already ouch told move didnt move dont talk nonsense either oh youre theyre stingy hot water im going get sick dont say make bathing worthless say ritual bath feel holy pure elated grumpy ruin whole experience thats okay comment everything enough already swear god cant say anything around dont swear see youre taking lord name vain one ten commandment worried think dont know tikva maybe thats right maybe youre afraid atonement isnt enough sin atone everyone else sin huh tell sin come tikva dont think knew cigarette smoked sabbath didnt separate milk meat watched tv friday night knew honey didnt say word liked way dont youve mended way fine enough god forgive dont worry u everyone take care account god im cold let go ettie never forgive rightly said wouldnt forgive cant live without stick like superglue even spy spy smelled cigarette bloodhound smell mile away smoke dont know bad dont say professor os hey yaffa honey okay darling fine yes nice meet naftali nice meet yeah well say well well see happy occasion best good night good night good night good night come let go babayof aaron babayof aaron babayof minute babayof aaron babayof live sir hanania rokah said even yet never early good deed good deed early big one writing bible scroll write bible scroll year good thats holy work come alone woman maam sorry oh wait writing bible scroll aaron who aaron oh aaron babayof live listen listen dont know anything told didnt order scroll would meeting scribe rabbi david asked thats whats got rabbi he temporarily helping aaron financial matter thats doesnt seem fishy hold money asks cant put two two together want rabbi soon ask dont worry well talk u nothing say brought made think plea keep treating like rabbi hell keep thinking claim isnt rabbi here chance tell nice he coming way talk little respect thats right respect little lot respect respect u quota man must respect wife himselfquot know didnt say maimonides said one tikva maimonides oh man genius good morning greeting greeting good morning rabbi good morning permission let explain importance scroll tikva know long sit silently wont seeing u thats well see manage without woman section excuse rabbi didnt mean understand theyre right angry look understand forefather jacob felt working year rachel hand year felt canopy removed veil stood none sister leah worked hard section deserve see reward sadly fate bad guy heartless thief listen understand choice im forced harden heart bow ritual law arent contribution daycare center memorial synagogue house lord rule sage studied every detail law synagogue ruled unconditionally bible scroll come woman section hand tied contradict great rabbi know wont easy great trial wife god willing bring new scroll theyll understand theyll say lucky happened way jacob looked six son leah bore said lucky happened way excuse rabbi david rabbi rabbi menashe getting better soon god willing hell strong congregation tricky situation im asking wait ruling id honored wait ruling os os margalit margalit go tikva tikva oh god lost mind frighten good sit one thing say order bible scroll im leaving youll come home empty house isnt rabbi ruling decision decision aaron want honest man thief im telling wont live thief leaving havent decided yet reserve duty dont forget take blood pressure pill ointment thank batsheva since collapse put mind isnt isnt manifest doesnt speak speak he detached reality example example speaks wife shes shes hospital unconscious recently started talking people even men old let say sir know day good day righteous man may creator grant long life grace kindness know batsheva who guest elijah prophet im professor yeshurun im doctor course written quotand yeshurun waxed fat kickedquot look he psychotic state probably extreme reaction wife condition batsheva well try medication see responds thank one pill day meal want see another three week three week three week repentance fateful day jewish people evil decree upon evil decree evil decree evil brings laundry oh dont silly wear im crazy arent crazy belong nuthouse ettie maybe ill get bed next tikva know look pretty like like really light face itd suit forget really leave alone try youll see forget tikva try forget youre stubborn missed whats goofball sweetie whats going running away mommy mustnt sweetie im sorry mr teitelbaum mr yazdi came ask dont mind boy visiting time gladly beg pardon mistake yes mistake know rabbi rabbi david praised rabbi said youre true righteous man isnt rabbi whats name rabbi david yeah rabbi david look im righteous man never boy see hears thing cant keep bubble like maybe shouldnt come sweetie take sweet day good sabbath good sabbath good sabbath good sabbath good sabbath kid supposed come let hope next sabbath geoula shes way dina ronit tova bracha coming tomorrow miriam still sure husband sasson doesnt feel well enough food le quotbless lord king universe quotwho sanctified u commanded u kindle sabbath lightsquot amen good sabbath quotbless lord king universe quotwho separate holy mundane light darkness quotthe jew nation 7th day day creation quotbless lord separate holy mundanequot amen good week good week good week good week dont know maybe mistake didnt hear word sabbath maybe theyre happier without u choice want rabbi coming nissan kind nissan want instead distancing drove right hand stand world wrapped around finger know many follower student worship honor much honor thats problem maybe time dishonor little flower thank thank coming wanted excuse get away trouble huh war room dont understand know youre crossing enemy line oh make sure arent watched look suspicious uhoh shes reporting u youre done aunt say u say shes like nothing hasnt said anything havent told everything thats going dont know shed take thought id wait see serious serious gave one flower call serious afraid shell say rabbi shed never say never tell shes well discus ill persuade serious twenty people violence god forbid course yes yes dont worry thank good night good thats taken care really going cant believe cant either choice honey come upstairs there lot work okay come rest little rest margalit kill im going come later going tell something bad time bad time crazy know long ive waited tell something hard try ask something say word whats story proposed gave flower big spender sweetheart rabbi doesnt mind dont know tomorrow exactly arent coming coming sweetie wont let embarrass outside window theyre looking next thing theyll throw peanut u let look sooner come better embarrassing ettie embarrassing dont silly said wed come join u get tired sit hold come stand straight higher stand see good yeah hello dear sister hello name gittie friend leah quotthank god making womanquot came right heard youre wonderful thing wed glad help lot experience protest recruit medium figure woman culture public official thank anything want hand flyer start naftali call lawyer want write warning every single mussayof woman warning rabbi slander libel disturbing peace anything get rid talmi go tell printer print poster vehement warning huge font xl paper say quotbeware disgraceful gathering gate holy house quotwe entreat every jew care fate israel quotplease stay away display immorality quotanyone pause quotis guilty desecration quotyou warned quotrun livesquot thats shocking voice shrill id better run life quothe fear god headquot quotheedquot woman whose synagogue mean doesnt decent woman section welcome join u woman woman men course want tell something maimonides said tikva say know maimonides rabbi moshe son wheres aaron havent seen age find tell need talk important thing student go front certainly courtyard move lesson rear classroom okay look come eat fruit salad fantastic try brought zion made sure definitely zion sends fruit salad think bribe make forget everything fruit salad enjoy honey good thing isnt youd eat well news pill helping yet take time mr zion ill go wash ill go see take time guest guest dont know guest guest told let anyone quotif money raised build synagogue quotand want use money something else quotit must used holier purposesquot like bible scroll hello zion good evening rabbi im read rabbi law see know zion best remedy soul scripture study dont mind bedtime quotmay god god fathersquot quotheal menashe son sarah quotheal cure strengthen grant wish quotplease lord heal himquot feel better rabbi rabbi lucky man youre loyal blind reality he bad shape zion realize cant delay important deed waiting ruling deed destroy congregation itll tear u apart youre mistaken zion congregation ruin day met since ive given\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Return top 5 most similar chunk_text\n",
    "top_k = 5\n",
    "top_documents = df1.loc[sorted_indices[:top_k], 'chunk_text'].tolist()\n",
    "print(\"Top 5 most similar chunk_text:\")\n",
    "for i, text in enumerate(top_documents, 1):\n",
    "    print(f\"Document {i}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "031486b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the chunk text to get semantic embeddings\n",
    "chunk_embeddings = model.encode(df1['chunk_text'].tolist())\n",
    "\n",
    "# Add the embeddings to the DataFrame\n",
    "df1['embeddings'] = chunk_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeadb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b2562",
   "metadata": {},
   "source": [
    "### **5. Store embeddings in a ChromaDB database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1556e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0769eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deec254",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=chromadb.chromadb.PersistentClient(path=r\"C:\\Users\\SRINU\\OneDrive\\Desktop\\searchEngine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6eadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "        name=\"searchengine\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"} # l2 is the default\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd862314",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, embedding in enumerate(chunk_embeddings):\n",
    "    collection.add(ids=f\"chunk_{i}\",  # Replace with a more descriptive ID scheme if needed\n",
    "                   embeddings=embedding.tolist(),  # Convert to a list for Chroma\n",
    "                   documents=df1.loc[i, \"chunk_text\"],  # Use chunk_text as documents\n",
    "                   metadatas={\"name\": df1.loc[i, \"name\"]}  # Use 'name' column data as metadata\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba21a35",
   "metadata": {},
   "source": [
    "# **Part 2: Retrieving Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55287834",
   "metadata": {},
   "source": [
    "**1. Take the user's search query.**\n",
    "\n",
    "**2. Preprocess the query (if required).**\n",
    "\n",
    "**3. Create query embedding.**\n",
    "\n",
    "**4. Using cosine distance, calculate the similarity score between embeddings of documents and user search query embedding.**\n",
    "\n",
    "**5. These cosine similarity scores will help in returning the most relevant candidate documents as per user's search query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931108e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0323f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle_text = \"help kiss excuse im gon na kiss need facial facial ouch thats gon na hurt tell straight english dont want wear wont force try okay go ahead dont like doesnt unlike doesnt like unli unlike fine give like doesnt dont right stay still sir tep really hurt love miss monica remember know say love hurt wow looking good hmm think look good mmm modern cool whats last one posh posh posh mama mae yeah ill posh mmhmm let posh mama mae ow ow im sorry hurt done bit ow ooh ow hand hurt sorry sorry sir please hold still look yuck dinner fork good salad fork good mmm okay \"\n",
    "cleaned_subtitle = clean_subtitle(subtitle_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c30959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the cleaned subtitle text to get semantic embeddings\n",
    "query_embedding = model.encode([cleaned_subtitle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc897d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query on the ChromaDB collection using the embeddings\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=5,\n",
    "    include=['documents']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04d562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents = results['documents']\n",
    "\n",
    "# Iterate over the documents and print each document\n",
    "for i, query_documents in enumerate(documents):\n",
    "    for j, document in enumerate(query_documents):\n",
    "        print(f\"Document {i+1}, Item {j+1}: {document}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fb607-d96c-457d-b5ad-ee0c5b0e78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf316e8-d5c9-4f8b-a700-166bf5f0f172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5c477-9ead-46ae-84e2-7ee3d12e29a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0411b73-8844-43b9-9d79-bfd428c7dcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9110dce-9c55-407e-99c7-253faca255d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef39511-2c17-4b17-9bef-36a01c45585f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d7b47-023c-4406-ab8a-c201b922f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dac207-6d3a-4ce3-9173-b41b417c9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'searchengine.pkl'\n",
    "\n",
    "# Dump the pipeline into the pickle file\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Pipeline dumped successfully to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fb755-e1cf-41e8-9568-a726a0a1d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'searchengine.pkl'\n",
    "\n",
    "# Load the pipeline from the pickle file\n",
    "with open(filename, 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208c14b-fdc0-405f-8e94-0279e6f74b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline.subtitle_text = \"help kiss excuse im gon na kiss need facial facial ouch thats gon na hurt tell straight english dont want wear wont force try okay go ahead dont like doesnt unlike doesnt like unli unlike fine give like doesnt dont right stay still sir tep really hurt love miss monica remember know say love hurt wow looking good hmm think look good mmm modern cool whats last one posh posh posh mama mae yeah ill posh mmhmm let posh mama mae ow ow im sorry hurt done bit ow ooh ow hand hurt sorry sorry sir please hold still look yuck dinner fork good salad fork good mmm okay \"\n",
    "cleaned_subtitle = clean_subtitle(subtitle_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c30c43-6c9c-427f-b065-d109c94385ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
